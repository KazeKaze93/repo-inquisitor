This file is a merged representation of the entire codebase, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
.gitignore
bin/inq-audit
bin/inq-detox
bin/inq-review
bin/inq-viz
LICENSE
package.json
python_src/analyzer.py
python_src/police.py
python_src/reviewer/ai_reviewer.py
python_src/reviewer/system_prompt.md
python_src/utils/__init__.py
python_src/utils/io_helper.py
README.md
requirements.txt
scripts/install.js
setup.sh
src/ai/context-packer.ts
src/analysis/anti_abstractor.cjs
src/analysis/dependency_detox.cjs
src/bridge.ts
src/cli.ts
src/index.ts
src/types.ts
src/viz/py_parser.py
src/viz/server.cjs
tsconfig.json
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="LICENSE">
Apache License
                           Version 2.0, January 2004
                        http://www.apache.org/licenses/

   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION

   1. Definitions.

      "License" shall mean the terms and conditions for use, reproduction,
      and distribution as defined by Sections 1 through 9 of this document.

      "Licensor" shall mean the copyright owner or entity authorized by
      the copyright owner that is granting the License.

      "Legal Entity" shall mean the union of the acting entity and all
      other entities that control, are controlled by, or are under common
      control with that entity. For the purposes of this definition,
      "control" means (i) the power, direct or indirect, to cause the
      direction or management of such entity, whether by contract or
      otherwise, or (ii) ownership of fifty percent (50%) or more of the
      outstanding shares, or (iii) beneficial ownership of such entity.

      "You" (or "Your") shall mean an individual or Legal Entity
      exercising permissions granted by this License.

      "Source" form shall mean the preferred form for making modifications,
      including but not limited to software source code, documentation
      source, and configuration files.

      "Object" form shall mean any form resulting from mechanical
      transformation or translation of a Source form, including but
      not limited to compiled object code, generated documentation,
      and conversions to other media types.

      "Work" shall mean the work of authorship, whether in Source or
      Object form, made available under the License, as indicated by a
      copyright notice that is included in or attached to the work
      (an example is provided in the Appendix below).

      "Derivative Works" shall mean any work, whether in Source or Object
      form, that is based on (or derived from) the Work and for which the
      editorial revisions, annotations, elaborations, or other modifications
      represent, as a whole, an original work of authorship. For the purposes
      of this License, Derivative Works shall not include works that remain
      separable from, or merely link (or bind by name) to the interfaces of,
      the Work and Derivative Works thereof.

      "Contribution" shall mean any work of authorship, including
      the original version of the Work and any modifications or additions
      to that Work or Derivative Works thereof, that is intentionally
      submitted to Licensor for inclusion in the Work by the copyright owner
      or by an individual or Legal Entity authorized to submit on behalf of
      the copyright owner. For the purposes of this definition, "submitted"
      means any form of electronic, verbal, or written communication sent
      to the Licensor or its representatives, including but not limited to
      communication on electronic mailing lists, source code control systems,
      and issue tracking systems that are managed by, or on behalf of, the
      Licensor for the purpose of discussing and improving the Work, but
      excluding communication that is conspicuously marked or otherwise
      designated in writing by the copyright owner as "Not a Contribution."

      "Contributor" shall mean Licensor and any individual or Legal Entity
      on behalf of whom a Contribution has been received by Licensor and
      subsequently incorporated within the Work.

   2. Grant of Copyright License. Subject to the terms and conditions of
      this License, each Contributor hereby grants to You a perpetual,
      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
      copyright license to reproduce, prepare Derivative Works of,
      publicly display, publicly perform, sublicense, and distribute the
      Work and such Derivative Works in Source or Object form.

   3. Grant of Patent License. Subject to the terms and conditions of
      this License, each Contributor hereby grants to You a perpetual,
      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
      (except as stated in this section) patent license to make, have made,
      use, offer to sell, sell, import, and otherwise transfer the Work,
      where such license applies only to those patent claims licensable
      by such Contributor that are necessarily infringed by their
      Contribution(s) alone or by combination of their Contribution(s)
      with the Work to which such Contribution(s) was submitted. If You
      institute patent litigation against any entity (including a
      cross-claim or counterclaim in a lawsuit) alleging that the Work
      or a Contribution incorporated within the Work constitutes direct
      or contributory patent infringement, then any patent licenses
      granted to You under this License for that Work shall terminate
      as of the date such litigation is filed.

   4. Redistribution. You may reproduce and distribute copies of the
      Work or Derivative Works thereof in any medium, with or without
      modifications, and in Source or Object form, provided that You
      meet the following conditions:

      (a) You must give any other recipients of the Work or
          Derivative Works a copy of this License; and

      (b) You must cause any modified files to carry prominent notices
          stating that You changed the files; and

      (c) You must retain, in the Source form of any Derivative Works
          that You distribute, all copyright, patent, trademark, and
          attribution notices from the Source form of the Work,
          excluding those notices that do not pertain to any part of
          the Derivative Works; and

      (d) If the Work includes a "NOTICE" text file as part of its
          distribution, then any Derivative Works that You distribute must
          include a readable copy of the attribution notices contained
          within such NOTICE file, excluding those notices that do not
          pertain to any part of the Derivative Works, in at least one
          of the following places: within a NOTICE text file distributed
          as part of the Derivative Works; within the Source form or
          documentation, if provided along with the Derivative Works; or,
          within a display generated by the Derivative Works, if and
          wherever such third-party notices normally appear. The contents
          of the NOTICE file are for informational purposes only and
          do not modify the License. You may add Your own attribution
          notices within Derivative Works that You distribute, alongside
          or as an addendum to the NOTICE text from the Work, provided
          that such additional attribution notices cannot be construed
          as modifying the License.

      You may add Your own copyright statement to Your modifications and
      may provide additional or different license terms and conditions
      for use, reproduction, or distribution of Your modifications, or
      for any such Derivative Works as a whole, provided Your use,
      reproduction, and distribution of the Work otherwise complies with
      the conditions stated in this License.

   5. Submission of Contributions. Unless You explicitly state otherwise,
      any Contribution intentionally submitted for inclusion in the Work
      by You to the Licensor shall be under the terms and conditions of
      this License, without any additional terms or conditions.
      Notwithstanding the above, nothing herein shall supersede or modify
      the terms of any separate license agreement you may have executed
      with Licensor regarding such Contributions.

   6. Trademarks. This License does not grant permission to use the trade
      names, trademarks, service marks, or product names of the Licensor,
      except as required for reasonable and customary use in describing the
      origin of the Work and reproducing the content of the NOTICE file.

   7. Disclaimer of Warranty. Unless required by applicable law or
      agreed to in writing, Licensor provides the Work (and each
      Contributor provides its Contributions) on an "AS IS" BASIS,
      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
      implied, including, without limitation, any warranties or conditions
      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
      PARTICULAR PURPOSE. You are solely responsible for determining the
      appropriateness of using or redistributing the Work and assume any
      risks associated with Your exercise of permissions under this License.

   8. Limitation of Liability. In no event and under no legal theory,
      whether in tort (including negligence), contract, or otherwise,
      unless required by applicable law (such as deliberate and grossly
      negligent acts) or agreed to in writing, shall any Contributor be
      liable to You for damages, including any direct, indirect, special,
      incidental, or consequential damages of any character arising as a
      result of this License or out of the use or inability to use the
      Work (including but not limited to damages for loss of goodwill,
      work stoppage, computer failure or malfunction, or any and all
      other commercial damages or losses), even if such Contributor
      has been advised of the possibility of such damages.

   9. Accepting Warranty or Additional Liability. While redistributing
      the Work or Derivative Works thereof, You may choose to offer,
      and charge a fee for, acceptance of support, warranty, indemnity,
      or other liability obligations and/or rights consistent with this
      License. However, in accepting such obligations, You may act only
      on Your own behalf and on Your sole responsibility, not on behalf
      of any other Contributor, and only if You agree to indemnify,
      defend, and hold each Contributor harmless for any liability
      incurred by, or claims asserted against, such Contributor by reason
      of your accepting any such warranty or additional liability.

   END OF TERMS AND CONDITIONS

   APPENDIX: How to apply the Apache License to your work.

      To apply the Apache License to your work, attach the following
      boilerplate notice, with the fields enclosed by brackets "[]"
      replaced with your own identifying information. (Don't include
      the brackets!)  The text should be enclosed in the appropriate
      comment syntax for the file format. We also recommend that a
      file or class name and description of purpose be included on the
      same "printed page" as the copyright notice for easier
      identification within third-party archives.

   Copyright [yyyy] [name of copyright owner]

   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
</file>

<file path="python_src/police.py">
import os
import sys
import re
import argparse

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from utils.io_helper import emit_success, emit_error, emit_log

PATTERNS = {
    "magic_hex": r'#[0-9a-fA-F]{3,6}',  # –ò—â–µ—Ç hex —Ü–≤–µ—Ç–∞
    "inline_style": r'style={{',         # –ò—â–µ—Ç –∏–Ω–ª–∞–π–Ω —Å—Ç–∏–ª–∏
    "raw_button": r'<button',            # –ò—â–µ—Ç —Å—ã—Ä—ã–µ –∫–Ω–æ–ø–∫–∏ (–¥–æ–ª–∂–µ–Ω –±—ã—Ç—å Button)
    "raw_input": r'<input',              # –ò—â–µ—Ç —Å—ã—Ä—ã–µ –∏–Ω–ø—É—Ç—ã (–¥–æ–ª–∂–µ–Ω –±—ã—Ç—å Input)
    "class_name_string": r'className="[^"]*\s{2,}[^"]*"'
}

IGNORE_FILES = ['tailwind.config.ts', 'vite.config.ts']

def scan_file(filepath: str):
    violations = []
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            lines = f.readlines()
            for i, line in enumerate(lines):
                line_num = i + 1
                
                if line.strip().startswith('//') or line.strip().startswith('/*'):
                    continue

                for code, pattern in PATTERNS.items():
                    matches = re.findall(pattern, line)
                    if matches:
                        if code == "magic_hex" and ("url(" in line or "id=" in line):
                            continue
                            
                        violations.append({
                            "type": code,
                            "line": line_num,
                            "match": matches[0],
                            "content": line.strip()[:50] + "..."
                        })
    except Exception as e:
        emit_log(f"Error reading {filepath}: {str(e)}")
        
    return violations

def inspect_codebase(target_path: str):
    report = {
        "total_violations": 0,
        "files_checked": 0,
        "files_with_violations": 0,
        "details": {} # filepath -> list of violations
    }
    
    logs = [f"üëÆ Starting Code Police Scan on: {target_path}"]

    for root, dirs, files in os.walk(target_path):
        for ignore in ['node_modules', 'dist', 'build', '.git', 'venv']:
            if ignore in dirs:
                dirs.remove(ignore)

        for file in files:
            if not file.endswith('.tsx'): # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ–ª—å–∫–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã (–ø–æ–∫–∞)
                continue
                
            if file in IGNORE_FILES:
                continue

            report["files_checked"] += 1
            full_path = os.path.join(root, file)
            
            rel_path = os.path.relpath(full_path, target_path)
            
            file_violations = scan_file(full_path)
            
            if file_violations:
                report["total_violations"] += len(file_violations)
                report["files_with_violations"] += 1
                report["details"][rel_path] = file_violations

    if report["total_violations"] > 0:
        logs.append(f"‚ùå FOUND {report['total_violations']} VIOLATIONS. CODEBASE IS DIRTY.")
    else:
        logs.append("‚úÖ Codebase is clean. Good job, Architect.")

    emit_success(data=report, logs=logs)

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("target", help="Directory to scan")
    args = parser.parse_args()
    
    inspect_codebase(os.path.abspath(args.target))
</file>

<file path="python_src/reviewer/ai_reviewer.py">
import os
import logging
import sys
import time
import re
from typing import Tuple, Optional

import google.generativeai as genai  
from github import Github, GithubException, Auth  
from google.api_core import exceptions as google_exceptions  
from google.generativeai.types import GenerationConfig  

# --- CONFIGURATION ---
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[logging.StreamHandler(sys.stdout)]
)
logger = logging.getLogger(__name__)

# Extensions to watch
REVIEWABLE_EXTENSIONS = ('.ts', '.tsx', '.js', '.css', '.sql', '.py', '.md', '.json', '.yml', '.toml')

# Models priority
MODEL_PRIORITIES = [
    "gemini-3-flash-preview",
    "gemini-2.5-flash",
    "gemini-2.5-flash-lite",
    "gemini-2.5-pro",
    "gemini-2.0-flash",
    "gemini-2.0-flash-lite",
    "gemini-2.0-pro",
]

DEFAULT_MODEL_NAME = "gemini-2.0-flash"

class ReviewerError(Exception):
    "Base class for reviewer script errors."
    pass

# Environment Variables
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
GITHUB_TOKEN = os.getenv("GITHUB_TOKEN")
REPO_NAME = os.getenv("REPO_NAME")
PR_NUMBER_STR = os.getenv("PR_NUMBER")
MODEL_NAME = os.getenv("MODEL_NAME", DEFAULT_MODEL_NAME)

def load_prompt() -> str:
    "Loads the system prompt from system_prompt.md file."
    try:
        script_dir = os.path.dirname(os.path.abspath(__file__))
        prompt_path = os.path.join(script_dir, 'system_prompt.md')
        
        with open(prompt_path, 'r', encoding='utf-8') as f:
            return f.read()
    except FileNotFoundError:
        if os.path.exists('system_prompt.md'):
            with open('system_prompt.md', 'r', encoding='utf-8') as f:
                return f.read()
        raise ReviewerError(f"system_prompt.md not found in {script_dir} or current dir!")

def get_pr_data() -> Tuple[object, str, str, str]:
    """
    Fetches PR diff AND context (Title/Description) from GitHub.
    Returns: (pr_object, diff_text, pr_title, pr_body)
    """
    if not GITHUB_TOKEN or not REPO_NAME or not PR_NUMBER_STR:
        raise ValueError("Missing GitHub credentials or PR info.")
    
    try:
        auth = Auth.Token(GITHUB_TOKEN)
        g = Github(auth=auth)
        
        repo = g.get_repo(REPO_NAME)
        pr = repo.get_pull(int(PR_NUMBER_STR))
        
        files = pr.get_files()
        diff_content = []
        
        logger.info(f"Processing PR #{PR_NUMBER_STR}: {pr.title}")

        for f in files:
            if f.status == "removed":
                continue
            
            if any(x in f.filename for x in ["package-lock.json", "yarn.lock", "pnpm-lock.yaml", "dist/", "out/", "build/", "repomix-output.xml"]):
                continue

            if f.filename.endswith(REVIEWABLE_EXTENSIONS):
                patch = f.patch if len(f.patch) < 20000 else f.patch[:20000] + "\n... [TRUNCATED]"
                diff_content.append(f"### File: {f.filename}\n```diff\n{patch}\n```")
        
        full_diff = "\n\n".join(diff_content)
        return pr, full_diff, pr.title, (pr.body or "No description provided.")
        
    except GithubException as e:
        logger.error(f"GitHub API Error: {e}")
        raise
    except ValueError as e:
        logger.error(f"Invalid PR number: {e}")
        raise

def analyze_code(diff_text: str, pr_title: str, pr_desc: str, system_prompt: str, model_name: str) -> Optional[str]:
    if not GEMINI_API_KEY:
        raise ReviewerError("GEMINI_API_KEY is missing.")

    genai.configure(api_key=GEMINI_API_KEY)
    model = genai.GenerativeModel(model_name)
    
    generation_config = GenerationConfig(
        max_output_tokens=8192,
        temperature=0.2,
    )
    
    # --- ENRICHED PROMPT WITH CONTEXT ---
    user_message = f"""
    {system_prompt}

    # CONTEXT
    **PR Title:** {pr_title}
    **PR Description:** {pr_desc}

    # INSTRUCTIONS
    Review the code changes below. 
    - Verify if the code changes match the PR intent described above.
    - If the user explicitly states they are removing a feature (like a Worker) for simplification, DO NOT flag it as a "Performance issue" unless it breaks the app completely.
    - Focus on Security, Bugs, and sloppy Types.

    <code_diff>
    {diff_text}
    </code_diff>
    """
    
    try:
        response = model.generate_content(user_message, generation_config=generation_config)
        return response.text
    except google_exceptions.GoogleAPIError as e:
        raise
    except Exception as e:
        raise ReviewerError(f"Unexpected error during analysis: {e}")

def parse_retry_delay(error_message: str) -> Optional[float]:
    patterns = [
        r'retry in (\d+(?:\.\d+)?) seconds?',
        r'retry after (\d+(?:\.\d+)?) seconds?',
        r'wait (\d+(?:\.\d+)?) seconds?',
    ]
    for pattern in patterns:
        match = re.search(pattern, error_message.lower())
        if match:
            try:
                return float(match.group(1))
            except (ValueError, IndexError):
                continue
    return None

def main() -> None:
    try:
        system_prompt = load_prompt()
        pr, diff_text, pr_title, pr_desc = get_pr_data()
        
        if not diff_text:
            logger.warning("No reviewable code changes found (or only ignored files).")
            return

        models_to_try = MODEL_PRIORITIES.copy()
        if MODEL_NAME and MODEL_NAME not in MODEL_PRIORITIES:
            models_to_try.insert(0, MODEL_NAME)

        review_comment = None
        successful_model = None
        last_error = None
        
        for model_name in models_to_try:
            try:
                logger.info(f"Analyzing with {model_name}...")
                
                review_comment = analyze_code(diff_text, pr_title, pr_desc, system_prompt, model_name)
                successful_model = model_name
                logger.info(f"Successfully analyzed with {model_name}")
                break
                
            except google_exceptions.GoogleAPIError as e:
                last_error = e
                logger.warning(f"API Error ({model_name}): {e}. Switching to next model...")
                time.sleep(1)
                continue
            except Exception as e:
                last_error = e
                logger.error(f"Error with {model_name}: {e}")
                continue
        
        if review_comment and successful_model:
            logger.info("Posting comment to GitHub...")
            final_comment = f"## üõ°Ô∏è –ê—Ä—Ö–∏—Ç–µ–∫—Ç–æ—Ä (AI Review)\n\n{review_comment}\n\n*Analyzed by: {successful_model}*"
            pr.create_issue_comment(final_comment)
            logger.info("Done.")
        else:
            logger.error(f"All models failed. Last error: {last_error}")
            sys.exit(1)
            
    except Exception as e:
        logger.critical(f"Fatal Reviewer Error: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
</file>

<file path="python_src/reviewer/system_prompt.md">
–¢—ã ‚Äî Senior Software Architect –ø—Ä–æ–µ–∫—Ç–∞ **NSFW Booru Client**.
–¢–≤–æ–π —Å—Ç–µ–∫: **Electron (Main/Renderer), React, TypeScript, Drizzle ORM, SQLite, Zustand**.

–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –ø—Ä–æ–≤–µ—Å—Ç–∏ –∂–µ—Å—Ç–∫–æ–µ –∏ —Ü–∏–Ω–∏—á–Ω–æ–µ Code Review.
–¢—ã –Ω–µ–Ω–∞–≤–∏–¥–∏—à—å "happy path", –±–ª–æ–∫–∏—Ä–æ–≤–∫—É Main-–ø—Ä–æ—Ü–µ—Å—Å–∞, `any`, –∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ —Ç–∏–ø–∏–∑–∞—Ü–∏–∏.

**–ì–õ–ê–í–ù–û–ï –ü–†–ê–í–ò–õ–û: –û–¢–í–ï–ß–ê–ô –°–¢–†–û–ì–û –ù–ê –†–£–°–°–ö–û–ú –Ø–ó–´–ö–ï.**

**–í–ê–ñ–ù–û: –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å –∏ –ö–æ–Ω—Ç–µ–∫—Å—Ç**
–¢—ã –ø–æ–ª—É—á–∏—à—å diff –∫–æ–¥–∞ –≤–Ω—É—Ç—Ä–∏ —Ç–µ–≥–æ–≤ `<code_diff>`. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–π –¢–û–õ–¨–ö–û —Ç–æ, —á—Ç–æ –≤–Ω—É—Ç—Ä–∏.

–¢–≤–æ–∏ –∫—Ä–∞—Å–Ω—ã–µ —Ñ–ª–∞–≥–∏ (–∏—â–∏ –∏—Ö –≤ –¥–∏—Ñ—Ñ–µ):

1. **Electron Security & IPC (–ö–†–ò–¢–ò–ß–ù–û)**:
   - **RCE**: –ü—Ä–æ–≤–µ—Ä–∫–∞ –ª—é–±—ã—Ö –¥–∞–Ω–Ω—ã—Ö, –ø—Ä–∏—Ö–æ–¥—è—â–∏—Ö –∏–∑ Renderer. –ù–∏–∫–∞–∫–æ–≥–æ `eval` –∏–ª–∏ –Ω–µ–±–µ–∑–æ–ø–∞—Å–Ω–æ–≥–æ `innerHTML`.
   - **Context Isolation**: –ü—Ä–æ–≤–µ—Ä—å, —á—Ç–æ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è `remote` –º–æ–¥—É–ª—å (–æ–Ω –º–µ—Ä—Ç–≤) –∏ –≤–∫–ª—é—á–µ–Ω `contextIsolation: true`.
   - **Preload Leaks**: –í `bridge.ts` –Ω–∞—Ä—É–∂—É –¥–æ–ª–∂–Ω—ã —Ç–æ—Ä—á–∞—Ç—å —Ç–æ–ª—å–∫–æ –º–µ—Ç–æ–¥—ã, –∞ –Ω–µ —Ü–µ–ª—ã–µ –æ–±—ä–µ–∫—Ç—ã Electron.

2. **Database & Data Integrity (Drizzle ORM)**:
   - **N+1 Queries**: –ü—Ä–æ–≤–µ—Ä—è–π, –Ω–µ –¥–µ–ª–∞—é—Ç—Å—è –ª–∏ –∑–∞–ø—Ä–æ—Å—ã –∫ –ë–î –≤–Ω—É—Ç—Ä–∏ —Ü–∏–∫–ª–æ–≤. –¢—Ä–µ–±—É–π `db.query...findMany` –∏–ª–∏ JOIN-—ã.
   - **Migrations**: –ï—Å–ª–∏ –º–µ–Ω—è–µ—Ç—Å—è —Å—Ö–µ–º–∞ (`schema.ts`), –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π SQL –∏–ª–∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –æ –º–∏–≥—Ä–∞—Ü–∏–∏.
   - **Type Safety**: Drizzle –¥–∞–µ—Ç —Ç–∏–ø—ã (`$inferSelect`). –ï—Å–ª–∏ –∫—Ç–æ-—Ç–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç `any` –≤–º–µ—Å—Ç–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ç–∏–ø–æ–≤ ‚Äî –±–µ–π –ø–æ —Ä—É–∫–∞–º.

3. **Performance (Main Process)**:
   - **Blocking the UI**: –¢—è–∂–µ–ª—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ (–ø–∞—Ä—Å–∏–Ω–≥ –æ–≥—Ä–æ–º–Ω—ã—Ö JSON, —Ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–æ–≤) –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–º–∏ –∏–ª–∏ –≤—ã–Ω–µ—Å–µ–Ω—ã –≤ Worker Threads.
   - **Image Handling**: –ù–∏–∫–∞–∫–æ–π –ø–µ—Ä–µ–¥–∞—á–∏ raw-buffer –∫–∞—Ä—Ç–∏–Ω–æ–∫ —á–µ—Ä–µ–∑ IPC. –¢–æ–ª—å–∫–æ –ø—É—Ç–∏ –∫ —Ñ–∞–π–ª–∞–º –∏–ª–∏ `blob:` URL.

4. **React & Clean Code**:
   - `useEffect` –±–µ–∑ –º–∞—Å—Å–∏–≤–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π.
   - –û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ `A11y` (–¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏) –Ω–∞ –∫–Ω–æ–ø–∫–∞—Ö –∏ –∏–Ω–ø—É—Ç–∞—Ö.
   - **Zustand**: –ü—Ä–æ–≤–µ—Ä—è–π, –Ω–µ —Å–æ–∑–¥–∞–µ—Ç—Å—è –ª–∏ –ª–∏—à–Ω–∏–π —Ä–µ-—Ä–µ–Ω–¥–µ—Ä –ø—Ä–∏ –ø–æ–¥–ø–∏—Å–∫–µ –Ω–∞ –≤–µ—Å—å —Å—Ç–æ—Ä.

**–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ (Markdown):**

–ï—Å–ª–∏ –∫–æ–¥ –∏–¥–µ–∞–ª–µ–Ω:
"LGTM üü¢. –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —á–∏—Å—Ç–∞, –Ω–æ —è —Å–ª–µ–∂—É –∑–∞ —Ç–æ–±–æ–π."

–ï—Å–ª–∏ –µ—Å—Ç—å –ø—Ä–æ–±–ª–µ–º—ã:

### üö® –ö—Ä–∏—Ç–∏—á–Ω–æ
[–£—è–∑–≤–∏–º–æ—Å—Ç–∏ IPC, –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞ Main-–ø—Ä–æ—Ü–µ—Å—Å–∞, SQL-–∏–Ω—ä–µ–∫—Ü–∏–∏ (—Ä–µ–¥–∫–æ —Å Drizzle, –Ω–æ –≤–æ–∑–º–æ–∂–Ω–æ —á–µ—Ä–µ–∑ raw sql)]

### ‚ö†Ô∏è –ù–∞–¥–æ –∏—Å–ø—Ä–∞–≤–∏—Ç—å
[–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å, N+1 –∑–∞–ø—Ä–æ—Å—ã, —Ç–∏–ø–∏–∑–∞—Ü–∏—è, A11y]

### üí° –°–æ–≤–µ—Ç
[–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è Drizzle –∑–∞–ø—Ä–æ—Å–æ–≤, —É–ª—É—á—à–µ–Ω–∏–µ UX, –Ω–µ–π–º–∏–Ω–≥]

**–ü–†–ê–í–ò–õ–û –õ–ê–ö–û–ù–ò–ß–ù–û–°–¢–ò:** –ù–µ –ø–µ—Ä–µ–ø–∏—Å—ã–≤–∞–π —Ñ–∞–π–ª—ã —Ü–µ–ª–∏–∫–æ–º. –ü–æ–∫–∞–∑—ã–≤–∞–π –¢–û–õ–¨–ö–û –∏–∑–º–µ–Ω–µ–Ω–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏.
</file>

<file path="src/index.ts">
export { PythonBridge } from "./bridge";

export * from "./types";
</file>

<file path=".gitignore">
# Dependencies
node_modules
venv/
__pycache__/
*.pyc

# Build outputs
dist/
out/
build/

# Logs
npm-debug.log*
yarn-debug.log*
yarn-error.log*

# Environment vars
.env
.env.local

# IDE
.vscode
.idea
*.swp
.git
</file>

<file path="bin/inq-audit">
#!/usr/bin/env node
// Symlink wrapper for anti_abstractor.cjs

require('../src/analysis/anti_abstractor.cjs');
</file>

<file path="python_src/analyzer.py">
import os
import sys
import argparse

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from utils.io_helper import emit_success, emit_error

def analyze_directory(target_path: str):
    if not os.path.exists(target_path):
        emit_error(f"Target path does not exist: {target_path}")

    stats = {
        "files": 0,
        "dirs": 0,
        "extensions": {},
        "total_size_bytes": 0
    }
    
    logs = []
    logs.append(f"Starting analysis of: {target_path}")

    try:
        for root, dirs, files in os.walk(target_path):
            if 'node_modules' in dirs:
                dirs.remove('node_modules')
            if 'venv' in dirs:
                dirs.remove('venv')
            if '.git' in dirs:
                dirs.remove('.git')

            stats["dirs"] += len(dirs)
            
            for file in files:
                stats["files"] += 1
                full_path = os.path.join(root, file)
                stats["total_size_bytes"] += os.path.getsize(full_path)
                
                ext = os.path.splitext(file)[1].lower() or "no_ext"
                stats["extensions"][ext] = stats["extensions"].get(ext, 0) + 1

        emit_success(data=stats, logs=logs)

    except Exception as e:
        emit_error(f"Analysis failed: {str(e)}")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Analyze a repository")
    parser.add_argument("target", help="Target directory to analyze")
    
    args = parser.parse_args()
    
    abs_target = os.path.abspath(args.target)
    
    analyze_directory(abs_target)
</file>

<file path="src/ai/context-packer.ts">
import * as fs from "fs";
import * as path from "path";

// === CONFIGURATION ===
const CONFIG = {
  rootDir: process.cwd(),
  aiDir: path.join(process.cwd(), ".ai"),
  outputFile: path.join(process.cwd(), ".ai", "GEMINI_PROMPT.txt"),
  rulesFile: path.join(process.cwd(), ".ai", "RULES.md"),

  includeDirs: ["src", "electron", "scripts", "python_src"],

  includeRootFiles: [
    "package.json",
    "tsconfig.json",
    "vite.config.ts",
    "electron.vite.config.ts",
    "tailwind.config.ts",
    "drizzle.config.ts",
    "repomix.config.json",
  ],

  ignorePatterns: [
    "node_modules",
    ".git",
    "dist",
    "out",
    "build",
    ".idea",
    ".vscode",
    "package-lock.json",
    "pnpm-lock.yaml",
    "yarn.lock",
    "*.log",
    "*.sqlite",
    "*.db",
    "*.png",
    "*.ico",
    "*.svg",
    "assets",
    "public",
    "context-packer.ts",
  ],

  // GEMINI 2.5 FLASH LIMITS (1M Input Tokens)
  // 1 Token ~= 4 chars. 1M tokens ~= 4MB text.
  // Avg line length ~= 60 chars.
  // Safe limit: ~65,000 - 100,000 lines.
  maxLinesPerFile: 5000,
  maxTotalLines: 100000,
};

// === HELPERS ===

const isIgnored = (filePath: string): boolean => {
  const relative = path.relative(CONFIG.rootDir, filePath);
  if (
    CONFIG.ignorePatterns.some(
      (p) => relative.includes(p) || filePath.endsWith(p)
    )
  )
    return true;

  const parts = relative.split(path.sep);
  if (parts.length === 1 && !CONFIG.includeRootFiles.includes(parts[0]))
    return true;
  if (parts.length > 1 && !CONFIG.includeDirs.includes(parts[0])) return true;

  return false;
};

const minifyAndTruncate = (content: string, filePath: string): string => {
  let lines = content.split("\n");
  lines = lines.filter((l) => l.trim().length > 0);

  if (lines.length > CONFIG.maxLinesPerFile) {
    const head = lines.slice(0, 100).join("\n");
    const tail = lines.slice(-100).join("\n");
    return `${head}\n\n... [SNIPPED ${
      lines.length - 200
    } LINES] ...\n\n${tail}`;
  }
  return lines.join("\n");
};

const generateTree = (dir: string, prefix = ""): string => {
  let tree = "";
  let files = [];
  try {
    files = fs.readdirSync(dir);
  } catch (e) {
    return "";
  }

  files.sort((a, b) => {
    const aPath = path.join(dir, a);
    const bPath = path.join(dir, b);
    try {
      const aStat = fs.statSync(aPath);
      const bStat = fs.statSync(bPath);
      if (aStat.isDirectory() && !bStat.isDirectory()) return -1;
      if (!aStat.isDirectory() && bStat.isDirectory()) return 1;
      return a.localeCompare(b);
    } catch {
      return 0;
    }
  });

  const filteredFiles = files.filter((file) => {
    const fullPath = path.join(dir, file);
    return !CONFIG.ignorePatterns.some(
      (p) => file === p || fullPath.includes("node_modules")
    );
  });

  filteredFiles.forEach((file, index) => {
    const fullPath = path.join(dir, file);
    const isLast = index === filteredFiles.length - 1;
    tree += `${prefix}${isLast ? "‚îî‚îÄ‚îÄ " : "‚îú‚îÄ‚îÄ "}${file}\n`;

    try {
      if (fs.statSync(fullPath).isDirectory()) {
        tree += generateTree(fullPath, prefix + (isLast ? "    " : "‚îÇ   "));
      }
    } catch {}
  });
  return tree;
};

// === MAIN ===

const run = () => {
  console.log("üî™ Surgical Context Packer v3 (High Capacity Mode)...");

  if (!fs.existsSync(CONFIG.aiDir))
    fs.mkdirSync(CONFIG.aiDir, { recursive: true });

  let userRules = "";
  if (fs.existsSync(CONFIG.rulesFile)) {
    userRules = fs.readFileSync(CONFIG.rulesFile, "utf-8");
    console.log("üìú Rules found.");
  } else {
    userRules = "No specific user rules defined.";
  }

  const treeString = generateTree(CONFIG.rootDir);

  let output = `
=== IDENTITY ===
You are a Senior Software Architect (Gemini 2.5 Flash).
Goal: Prevent "UI drift" and spaghetti code.

=== USER RULES ===
${userRules}

=== PROJECT STRUCTURE ===
\`\`\`
${treeString}
\`\`\`

=== SOURCE CODE ===
`;

  let totalLines = 0;
  let fileCount = 0;

  const processFile = (filePath: string) => {
    if (isIgnored(filePath)) return;

    const ext = path.extname(filePath);
    if (
      ![
        ".ts",
        ".tsx",
        ".js",
        ".cjs",
        ".json",
        ".py",
        ".css",
        ".sql",
        ".md",
        ".html",
      ].includes(ext)
    )
      return;

    try {
      const content = fs.readFileSync(filePath, "utf-8");
      const relative = path.relative(CONFIG.rootDir, filePath);
      const processed = minifyAndTruncate(content, filePath);

      output += `\n<file path="${relative}">\n${processed}\n</file>\n`;
      totalLines += processed.split("\n").length;
      fileCount++;
    } catch (e) {
      console.warn(`‚ö†Ô∏è Failed to read ${filePath}`);
    }
  };

  const traverseDir = (dir: string) => {
    if (!fs.existsSync(dir)) return;
    const files = fs.readdirSync(dir);
    files.forEach((f) => {
      const fullPath = path.join(dir, f);
      const stat = fs.statSync(fullPath);
      if (stat.isDirectory()) traverseDir(fullPath);
      else processFile(fullPath);
    });
  };

  CONFIG.includeRootFiles.forEach((f) => {
    const p = path.join(CONFIG.rootDir, f);
    if (fs.existsSync(p)) processFile(p);
  });

  CONFIG.includeDirs.forEach((d) => traverseDir(path.join(CONFIG.rootDir, d)));

  output += `
\n=== INSTRUCTION ===
Await my next command.
`;

  fs.writeFileSync(CONFIG.outputFile, output);

  const sizeMB = (fs.statSync(CONFIG.outputFile).size / (1024 * 1024)).toFixed(
    2
  );

  console.log(`‚úÖ GEMINI PROMPT GENERATED: ${CONFIG.outputFile}`);
  console.log(`   Files: ${fileCount} | Lines: ~${totalLines}`);
  console.log(`   Size: ${sizeMB} MB`);

  if (totalLines > CONFIG.maxTotalLines) {
    console.warn(`‚ö†Ô∏è  OVERFLOW: ${totalLines} lines. Might exceed 1M tokens.`);
  } else {
    console.log(`‚ú® Fits comfortably within Gemini 2.5 Flash context.`);
  }
};

run();
</file>

<file path="tsconfig.json">
{
  "compilerOptions": {
    "target": "ES2020",
    "module": "commonjs",
    "lib": ["ES2020"],
    "outDir": "./dist",
    "rootDir": "./src",
    "strict": true,
    "esModuleInterop": true,
    "skipLibCheck": true,
    "forceConsistentCasingInFileNames": true,
    "resolveJsonModule": true,
    "declaration": true,
    "declarationMap": true,
    "sourceMap": true,
    "moduleResolution": "node"
  },
  "include": ["src/**/*"],
  "exclude": ["node_modules", "dist"]
}
</file>

<file path="package.json">
{
  "name": "@kazekaze93/repo-inquisitor",
  "version": "1.0.0",
  "bin": {
    "inquisitor": "./dist/cli.js"
  },
  "main": "dist/index.js",
  "types": "dist/index.d.ts",
  "scripts": {
    "build": "tsc",
    "prepare": "npm run build",
    "setup:python": "node scripts/install.js",
    "postinstall": "node scripts/install.js"
  },
  "files": [
    "dist",
    "scripts",
    "requirements.txt",
    "python_src",
    "src",
    "README.md"
  ],
  "devDependencies": {
    "@types/node": "^25.0.3",
    "typescript": "^5.0.0"
  },
  "dependencies": {
    "repomix": "^1.11.0"
  }
}
</file>

<file path="src/analysis/anti_abstractor.cjs">
const fs = require("fs");
const path = require("path");

const IGNORED_SUFFIXES = [
  "Props",
  "State",
  "DTO",
  "Response",
  "Request",
  "Params",
  "Config",
  "Option",
  "Item",
];
const IGNORED_FILES = [".d.ts"];

class AntiAbstractor {
  constructor(rootDir) {
    this.rootDir = rootDir;
    this.registry = new Map();
    this.filesContent = new Map();
  }

  scan() {
    if (!fs.existsSync(this.rootDir)) {
      console.error(`‚ùå –ü—É—Ç—å –Ω–µ –Ω–∞–π–¥–µ–Ω: ${this.rootDir}`);
      process.exit(1);
    }

    console.log(`üîç –°–∫–∞–Ω–∏—Ä—É–µ–º (v2) TypeScript —Ñ–∞–π–ª—ã –≤ ${this.rootDir}...`);

    this.walk(this.rootDir, (filePath, content) => {
      this.findDefinitions(filePath, content);
      this.filesContent.set(filePath, content);
    });

    console.log(
      `üìä –ù–∞–π–¥–µ–Ω–æ ${this.registry.size} —Å—É—â–Ω–æ—Å—Ç–µ–π. –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ...`
    );

    for (const [name, info] of this.registry) {
      const regex = new RegExp(`\\b${name}\\b`, "g");

      for (const [filePath, content] of this.filesContent) {
        const matches = content.match(regex);
        if (matches) {
          info.count += matches.length;
        }
      }
    }

    this.judge();
  }

  walk(dir, callback) {
    const files = fs.readdirSync(dir);
    for (const file of files) {
      const filePath = path.join(dir, file);
      const stat = fs.statSync(filePath);

      if (stat.isDirectory()) {
        if (
          file !== "node_modules" &&
          file !== ".git" &&
          file !== "dist" &&
          file !== "out"
        ) {
          this.walk(filePath, callback);
        }
      } else if (file.endsWith(".ts") || file.endsWith(".tsx")) {
        const content = fs.readFileSync(filePath, "utf-8");
        callback(filePath, content);
      }
    }
  }

  findDefinitions(filePath, content) {
    const defRegex =
      /(?:export\s+)?(?:interface|type|class|enum|abstract\s+class)\s+([A-Z][a-zA-Z0-9_]*)/g;

    let match;
    while ((match = defRegex.exec(content)) !== null) {
      const name = match[1];

      if (IGNORED_SUFFIXES.some((suffix) => name.endsWith(suffix))) continue;

      if (!this.registry.has(name)) {
        this.registry.set(name, {
          defPath: filePath,
          count: 0,
        });
      }
    }
  }

  judge() {
    let foundGuilty = false;
    console.log("\n--- –û–¢–ß–ï–¢ –ò–ù–ö–í–ò–ó–ò–¶–ò–ò (V2) ---\n");

    for (const [name, info] of this.registry) {
      if (info.defPath.endsWith(".d.ts")) continue;

      if (info.count <= 1) {
        console.log(`üíÄ –ú–ï–†–¢–í–´–ô –ö–û–î:`);
        console.log(`   –°—É—â–Ω–æ—Å—Ç—å: ${name}`);
        console.log(`   –§–∞–π–ª: ${info.defPath}`);
        console.log(`   –°—Ç–∞—Ç—É—Å: 0 –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–π.`);
        console.log(`   üëâ \x1b[31m¬´–¢—ã –Ω–µ Google, —É–¥–∞–ª–∏ —ç—Ç–æ.¬ª\x1b[0m\n`);
        foundGuilty = true;
      } else if (info.count === 2 && name.startsWith("I")) {
        console.log(`‚ö†Ô∏è –ü–†–ï–ñ–î–ï–í–†–ï–ú–ï–ù–ù–ê–Ø –ê–ë–°–¢–†–ê–ö–¶–ò–Ø:`);
        console.log(`   –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å: ${name}`);
        console.log(`   –§–∞–π–ª: ${info.defPath}`);
        console.log(`   –°—Ç–∞—Ç—É—Å: –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤—Å–µ–≥–æ –≤ 1 –º–µ—Å—Ç–µ.`);
        console.log(
          `   üëâ \x1b[33m¬´YAGNI. –ó–∞—á–µ–º —Ç–µ–±–µ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å —Ä–∞–¥–∏ –æ–¥–Ω–æ–≥–æ –∫–ª–∞—Å—Å–∞?¬ª\x1b[0m\n`
        );
        foundGuilty = true;
      }
    }

    if (!foundGuilty) {
      console.log("‚úÖ –¢–µ–ø–µ—Ä—å —á–µ—Å—Ç–Ω–æ. –Ø–≤–Ω–æ–≥–æ –º—É—Å–æ—Ä–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.");
    }
  }
}

const targetDir = process.argv[2];
if (!targetDir) {
  console.log("Usage: node scripts/anti_abstractor.cjs <path_to_src>");
  process.exit(1);
}

new AntiAbstractor(targetDir).scan();
</file>

<file path="src/analysis/dependency_detox.cjs">
const fs = require("fs");
const path = require("path");
const { execSync } = require("child_process");

const SAFE_BUILD_TOOLS = [
  "typescript",
  "eslint",
  "prettier",
  "vite",
  "electron",
  "electron-builder",
  "electron-vite",
  "tailwindcss",
  "postcss",
  "autoprefixer",
  "drizzle-kit",
  "repomix",
  "globals",
  "@types/node",
  "@types/react",
  "@types/react-dom",
  "concurrently",
  "wait-on",
  "cross-env",
  "rimraf",
  "basedpyright",
];

const SINGLETON_PATTERNS = [
  "@radix-ui",
  "@headlessui",
  "zod",
  "zustand",
  "i18next",
  "better-sqlite3",
  "electron-log",
  "lucide-react",
  "clsx",
  "tailwind-merge",
];

const SHAME_LIST = {
  lodash: "–ò—Å–ø–æ–ª—å–∑—É–π –Ω–∞—Ç–∏–≤–Ω—ã–π JS. –¢—ã –Ω–µ –≤ 2015-–º.",
  moment: "–°–ª–∏—à–∫–æ–º –∂–∏—Ä–Ω—ã–π. –ë–µ—Ä–∏ date-fns –∏–ª–∏ Intl.",
  axios: "–£ —Ç–µ–±—è –µ—Å—Ç—å fetch(). –ó–∞—á–µ–º –ª–∏—à–Ω–∏–µ 20–∫–±?",
  "is-odd": "–°–µ—Ä—å–µ–∑–Ω–æ? –£–¥–∞–ª—è–π.",
  uuid: "crypto.randomUUID() –µ—Å—Ç—å –≤ –ø–ª–∞—Ç—Ñ–æ—Ä–º–µ.",
};

class DependencyDetox {
  constructor(rootDir) {
    this.rootDir = rootDir;
    this.srcDir = path.join(rootDir, "src");
    this.pkgFile = path.join(rootDir, "package.json");
    this.totalFiles = 0;
    this.pkgData = {};
  }

  run(mode, targetPkg) {
    if (!fs.existsSync(this.pkgFile)) {
      console.error("‚ùå –ù–µ—Ç package.json.");
      process.exit(1);
    }

    this.pkgData = JSON.parse(fs.readFileSync(this.pkgFile, "utf-8"));

    if (mode === "nuke") {
      this.nuke(targetPkg);
    } else {
      this.analyze();
    }
  }

  analyze() {
    console.log("üíä –ù–∞—á–∏–Ω–∞–µ–º –¥–µ—Ç–æ–∫—Å–∏–∫–∞—Ü–∏—é –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π (V2 - Smart Mode)...\n");

    const deps = {
      ...this.pkgData.dependencies,
      ...this.pkgData.devDependencies,
    };
    const depNames = Object.keys(deps);

    const fileContents = [];
    this.walk(this.srcDir, (f, content) => {
      fileContents.push(content);
      this.totalFiles++;
    });

    const configContents = [];
    const configFiles = fs
      .readdirSync(this.rootDir)
      .filter(
        (f) => f.includes("config") || f.endsWith(".js") || f.endsWith(".ts")
      );
    configFiles.forEach((f) => {
      if (fs.statSync(path.join(this.rootDir, f)).isFile()) {
        configContents.push(
          fs.readFileSync(path.join(this.rootDir, f), "utf-8")
        );
      }
    });

    const scriptsContent = JSON.stringify(this.pkgData.scripts || {});

    console.log(
      `üìÇ –ü—Ä–æ—Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–æ: ${this.totalFiles} —Ñ–∞–π–ª–æ–≤ –∫–æ–¥–∞ + –∫–æ–Ω—Ñ–∏–≥–∏ + —Å–∫—Ä–∏–ø—Ç—ã.`
    );
    console.log(`üì¶ –ü—Ä–æ–≤–µ—Ä–∫–∞ ${depNames.length} –ø–∞–∫–µ—Ç–æ–≤...`);
    console.log("-".repeat(85));
    console.log(`| %-30s | %-10s | %-35s |`, "Package", "Usages", "Verdict");
    console.log("-".repeat(85));

    depNames.sort().forEach((dep) => {
      const regex = new RegExp(
        `(?:from|require\\()\\s*['"]${dep}(?:/.*)?['"]`,
        "g"
      );
      const simpleRegex = new RegExp(`${dep}`, "g");

      let usages = 0;
      let configUsages = 0;
      let scriptUsages = 0;

      fileContents.forEach((c) => {
        if (c.match(regex)) usages++;
      });

      configContents.forEach((c) => {
        if (c.match(simpleRegex)) configUsages++;
      });

      if (scriptsContent.match(simpleRegex)) scriptUsages++;

      this.printVerdict(dep, usages, configUsages, scriptUsages);
    });
    console.log("-".repeat(85));
  }

  printVerdict(dep, usages, configUsages, scriptUsages) {
    let verdict = "‚úÖ OK";
    let color = "\x1b[32m"; // Green
    const totalRefs = usages + configUsages + scriptUsages;

    const isSafeTool = SAFE_BUILD_TOOLS.some((t) => dep.includes(t));
    const isSingleton = SINGLETON_PATTERNS.some((p) => dep.startsWith(p));
    const isSystem =
      dep.startsWith("@types") || dep.startsWith("eslint-plugin");

    if (totalRefs === 0) {
      if (isSafeTool || isSystem) {
        verdict = "üõ°Ô∏è  TOOL/SYS (–°–∫—Ä—ã—Ç–æ–µ –∏—Å–ø.)";
        color = "\x1b[36m"; // Cyan
      } else {
        verdict = "üëª GHOST (–£–¥–∞–ª—è–π!)";
        color = "\x1b[31m"; // Red
      }
    } else if (usages === 1) {
      if (isSingleton) {
        verdict = "üíé WRAPPER/SINGLETON (–û–∫)";
        color = "\x1b[32m";
      } else if (configUsages > 0 || scriptUsages > 0) {
        verdict = "‚öôÔ∏è  CONFIGURED";
        color = "\x1b[32m";
      } else {
        verdict = "‚ö†Ô∏è LAZY (1 usage)";
        color = "\x1b[33m"; // Yellow
      }
    } else if (usages < 3 && !isSystem && !isSafeTool && !isSingleton) {
      verdict = "‚ö†Ô∏è LOW USAGE";
      color = "\x1b[33m";
    }

    if (SHAME_LIST[dep] && totalRefs > 0) {
      verdict = `üí© SHAME: ${SHAME_LIST[dep]}`;
      color = "\x1b[35m";
    }

    const usageStr = `${usages} (src) / ${configUsages + scriptUsages} (cfg)`;
    console.log(`${color}| %-30s | %-10s | %s\x1b[0m`, dep, usageStr, verdict);
  }

  nuke(targetPkg) {
    if (!targetPkg) {
      console.error(
        "‚ùå –£–∫–∞–∂–∏ –ø–∞–∫–µ—Ç: node scripts/dependency_detox.cjs --nuke <pkg>"
      );
      process.exit(1);
    }
    console.log(`\nüß® –†–ï–ñ–ò–ú –•–ê–û–°–ê: –£–¥–∞–ª—è–µ–º ${targetPkg}...`);
    try {
      execSync(`npm uninstall ${targetPkg}`, { stdio: "inherit" });
      console.log(`üèóÔ∏è  –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–∏–ø–æ–≤ (–±—ã—Å—Ç—Ä–µ–µ, —á–µ–º –±–∏–ª–¥)...`);
      execSync("npx tsc --noEmit", { stdio: "inherit" });
      console.log(`\nü§Ø –ü–†–û–ï–ö–¢ –ñ–ò–í! ${targetPkg} –±—ã–ª –±–µ—Å–ø–æ–ª–µ–∑–µ–Ω.`);
    } catch (error) {
      console.log(`\nüí• –û–®–ò–ë–ö–ê. –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç—å –Ω—É–∂–Ω–∞.`);
      console.log(`üöë Rollback...`);
      execSync(`npm install ${targetPkg}`, { stdio: "inherit" });
    }
  }

  walk(dir, callback) {
    if (!fs.existsSync(dir)) return;
    const files = fs.readdirSync(dir);
    for (const file of files) {
      const filePath = path.join(dir, file);
      const stat = fs.statSync(filePath);
      if (stat.isDirectory()) {
        this.walk(filePath, callback);
      } else if (/\.(ts|tsx|js|jsx)$/.test(file)) {
        callback(filePath, fs.readFileSync(filePath, "utf-8"));
      }
    }
  }
}

const args = process.argv.slice(2);
const mode = args.includes("--nuke") ? "nuke" : "scan";
const pkgName = args[args.indexOf("--nuke") + 1];

new DependencyDetox(process.cwd()).run(mode, pkgName);
</file>

<file path="src/bridge.ts">
import { spawn } from "child_process";
import path from "path";
import fs from "fs";
import os from "os";
import { PythonExecutionResult, BridgeOptions } from "./types";

export class PythonBridge {
  private pythonPath: string;

  constructor(options: BridgeOptions = {}) {
    this.pythonPath = options.pythonPath || this.resolvePythonPath();
  }

  private resolvePythonPath(): string {
    const isWindows = os.platform() === "win32";

    const potentialRoots = [
      path.resolve(__dirname, ".."),
      path.resolve(__dirname, "..", ".."),
    ];

    for (const root of potentialRoots) {
      const venvPath = isWindows
        ? path.join(root, "venv", "Scripts", "python.exe")
        : path.join(root, "venv", "bin", "python");

      if (fs.existsSync(venvPath)) {
        return venvPath;
      }
    }

    return isWindows ? "python" : "python3";
  }

  public async executeScript<T>(
    scriptPath: string,
    args: string[] = []
  ): Promise<PythonExecutionResult<T>> {
    return new Promise((resolve) => {
      if (!fs.existsSync(scriptPath)) {
        resolve({
          success: false,
          error: `Python script not found at path: ${scriptPath}`,
        });
        return;
      }

      const proc = spawn(this.pythonPath, [scriptPath, ...args]);

      let stdoutData = "";
      let stderrData = "";

      proc.stdout.on("data", (data) => {
        stdoutData += data.toString();
      });

      proc.stderr.on("data", (data) => {
        stderrData += data.toString();
      });

      proc.on("close", (code) => {
        const logs: string[] = [];
        let parsedData: T | undefined;
        let success = code === 0;
        let error = stderrData.trim();

        const lines = stdoutData
          .trim()
          .split("\n")
          .filter((line) => line.length > 0);

        if (lines.length > 0) {
          const lastLine = lines[lines.length - 1];
          try {
            parsedData = JSON.parse(lastLine);
            lines.pop();
          } catch (e) {
            // Ignore if last line is not JSON
          }
        }

        logs.push(...lines);

        resolve({
          success,
          data: parsedData,
          error: success ? undefined : error,
          logs,
        });
      });

      proc.on("error", (err) => {
        resolve({
          success: false,
          error: `Process spawn error: ${err.message}`,
        });
      });
    });
  }
}
</file>

<file path="src/cli.ts">
#!/usr/bin/env node
import path from "path";
import { fork } from "child_process";
import { PythonBridge } from "./bridge";

// === CONFIGURATION ===

type CommandType = "python" | "node";

interface CommandDef {
  type: CommandType;
  file: string; // Relative to package root
  description: string;
}

// –†–µ–µ—Å—Ç—Ä –∫–æ–º–∞–Ω–¥
const COMMANDS: Record<string, CommandDef> = {
  // üêç Python Tools
  analyze: {
    type: "python",
    file: "python_src/analyzer.py",
    description: "Analyze file statistics and types (Python)",
  },
  police: {
    type: "python",
    file: "python_src/police.py",
    description: "Scan for forbidden patterns & styles (Python)",
  },
  review: {
    type: "python",
    file: "python_src/reviewer/ai_reviewer.py",
    description: "AI Code Reviewer (Gemini + GitHub) (Python)",
  },

  // üü¢ Node Tools
  audit: {
    type: "node",
    file: "src/analysis/anti_abstractor.cjs",
    description: "Find dead code and over-abstractions (Node)",
  },
  detox: {
    type: "node",
    file: "src/analysis/dependency_detox.cjs",
    description: "Analyze and clean unused dependencies (Node)",
  },
  viz: {
    type: "node",
    file: "src/viz/server.cjs",
    description: "Start interactive dependency visualizer (Node)",
  },

  ctx: {
    type: "node",
    file: "dist/ai/context-packer.js",
    description: "Pack full project context for Gemini 2.5 (Node)",
  },
};

// === HELPERS ===

function printHelp() {
  console.log(`
üïµÔ∏è  \x1b[1mREPO INQUISITOR\x1b[0m - The Hybrid Audit Tool

\x1b[33mUsage:\x1b[0m
  inquisitor <command> [arguments]

\x1b[33mCommands:\x1b[0m`);

  const maxLen = Math.max(...Object.keys(COMMANDS).map((k) => k.length));

  for (const [name, def] of Object.entries(COMMANDS)) {
    const paddedName = name.padEnd(maxLen + 2);
    const icon = def.type === "python" ? "üêç" : "üü¢";
    console.log(`  ${paddedName} ${icon} ${def.description}`);
  }

  console.log(`
\x1b[33mExamples:\x1b[0m
  inquisitor analyze ./src
  inquisitor review (requires ENV vars)
  inquisitor ctx:pack
`);
}

// === MAIN ===

async function main() {
  const args = process.argv.slice(2);
  const commandName = args[0];

  // 1. Handle Help or Empty
  if (!commandName || args.includes("--help") || args.includes("-h")) {
    printHelp();
    process.exit(0);
  }

  // 2. Validate Command
  const command = COMMANDS[commandName];
  if (!command) {
    console.error(`‚ùå Unknown command: "${commandName}"`);
    console.error(`Run "inquisitor --help" to see available commands.`);
    process.exit(1);
  }

  const scriptArgs = args.slice(1);
  const projectRoot = path.resolve(__dirname, ".."); // Up from dist/ to root

  console.log(
    `üöÄ Executing \x1b[36m${commandName}\x1b[0m [${command.type}]...`
  );

  // 3. Execute
  if (command.type === "python") {
    // --- PYTHON EXECUTION ---
    const bridge = new PythonBridge();
    const scriptPath = path.join(projectRoot, command.file);

    try {
      // Pass Env Vars explicitly for AI Reviewer
      const result = await bridge.executeScript(scriptPath, scriptArgs);

      if (result.logs && result.logs.length > 0) {
        console.log("\n--- Logs ---");
        result.logs.forEach((l) => console.log(l));
      }

      if (result.success) {
        if (result.data) {
          console.log("\n--- Result ---");
          console.log(JSON.stringify(result.data, null, 2));
        }
      } else {
        console.error("\nüí• Python Error:");
        console.error(result.error);
        process.exit(1);
      }
    } catch (err) {
      console.error("üíÄ Bridge Crash:", err);
      process.exit(1);
    }
  } else {
    // --- NODE EXECUTION ---
    const scriptPath = path.join(projectRoot, command.file);

    // Forking allows the script to have its own process.argv and isolation
    const child = fork(scriptPath, scriptArgs, {
      stdio: "inherit",
      env: { ...process.env, FORCE_COLOR: "1" },
    });

    child.on("exit", (code) => {
      process.exit(code ?? 0);
    });

    child.on("error", (err) => {
      // Fallback: If .js not found (maybe running locally in dev without build), try .ts with tsx?
      // For now, just error out cleanly.
      console.error(`‚ùå Failed to start Node script: ${scriptPath}`);
      console.error(`Make sure you ran 'npm run build' so dist/ files exist.`);
    });
  }
}

main();
</file>

<file path="bin/inq-detox">
#!/usr/bin/env node
// Symlink wrapper for dependency_detox.cjs

require('../src/analysis/dependency_detox.cjs');
</file>

<file path="bin/inq-review">
#!/usr/bin/env node
// Symlink wrapper for ai_reviewer.py
// On Windows, this should be a batch file or use node to execute python

const { spawn } = require('child_process');
const path = require('path');

const scriptPath = path.join(__dirname, '..', 'src', 'reviewer', 'ai_reviewer.py');
const python = process.platform === 'win32' ? 'python' : 'python3';

const child = spawn(python, [scriptPath, ...process.argv.slice(2)], {
  stdio: 'inherit',
  cwd: process.cwd()
});

child.on('error', (err) => {
  console.error(`Error executing ai_reviewer.py: ${err.message}`);
  process.exit(1);
});

child.on('exit', (code) => {
  process.exit(code || 0);
});
</file>

<file path="bin/inq-viz">
#!/usr/bin/env node
// Symlink wrapper for server.cjs

require('../src/viz/server.cjs');
</file>

<file path="python_src/utils/__init__.py">
"""
Python Bridge utilities package.
"""

from .io_helper import emit_success, emit_error, emit_log

__all__ = ["emit_success", "emit_error", "emit_log"]
</file>

<file path="README.md">
## üì¶ Repo Inquisitor

> **Hybrid Node + Python toolkit for repository analysis and code quality.**  
> TypeScript on the outside, Python on the inside.

`@kazekaze93/repo-inquisitor` is a comprehensive audit and analysis toolkit that:

- **Bridges Node ‚Üî Python** via a thin `child_process` wrapper (`PythonBridge`).
- **Bootstraps a Python venv** on install (`scripts/install.js` + `requirements.txt`).
- Exposes a **CLI entrypoint** `inquisitor` with multiple analysis commands.
- Provides **code analysis tools** (dead code detection, dependency cleanup, style checking).
- Includes **AI-powered code review** using Gemini API.
- Features **dependency visualization** and **context packing** for AI models.

The goal is to keep the integration minimal and explicit, not to build Yet Another Framework‚Ñ¢.

## üèó Architecture

- **Node side:** TypeScript, compiled to `dist/`. Public surface is in `src/index.ts`.
- **Python side:** Plain Python scripts in `python_src/` (and subpackages), executed as child processes.
- **Bridge:** `PythonBridge` looks for a local `venv` first, then falls back to `python`/`python3` in `PATH`.
- **CLI:** `bin.inquisitor -> dist/cli.js` ‚Üí resolves a command ‚Üí picks a Python script ‚Üí runs it via the bridge.

No hidden daemons, no sockets, just `spawn(python, script.py, args...)` and a bit of JSON parsing.

## üöÄ Installation

Install from npm (or from Git if you prefer):

```bash
npm install @kazekaze93/repo-inquisitor
# or
npm install git+ssh://git@github.com:YOUR_ORG/repo-inquisitor.git
```

On install, the `postinstall` hook will **try to set up Python** via `scripts/install.js`.  
If that fails (no Python, corporate laptop, etc.), you can run it manually:

```bash
npm run setup:python
```

The setup script will:

1. Check that Python 3 is available in `PATH`.
2. Create a `venv` in the project root.
3. Install dependencies from `requirements.txt` (if/when you add them).

## üõ† Usage (as a library)

```ts
import { PythonBridge } from "@kazekaze93/repo-inquisitor";

const bridge = new PythonBridge();

async function run() {
  const result = await bridge.executeScript("/absolute/path/to/script.py", [
    "arg1",
    "arg2",
  ]);

  if (result.success) {
    console.log("Python data:", result.data);
  } else {
    console.error("Python error:", result.error);
  }
}

run().catch((err) => {
  console.error("Bridge failure:", err);
});
```

The bridge assumes that the Python script:

- Prints **logs** as normal stdout lines.
- Prints **JSON on the last line** (parsed into `result.data`).

## üß∞ Usage (CLI)

After installing, you get an `inquisitor` binary on your `PATH`:

```bash
npx inquisitor <command> [...args]
```

### Available Commands

#### üêç Python Tools

- **`analyze`** - Analyze file statistics and types (Python)

  ```bash
  inquisitor analyze ./src
  ```

- **`police`** - Scan for forbidden patterns & styles (Python)

  ```bash
  inquisitor police ./src
  ```

- **`review`** - AI Code Reviewer using Gemini + GitHub (Python)
  ```bash
  # Requires GEMINI_API_KEY and GITHUB_TOKEN environment variables
  inquisitor review
  ```

#### üü¢ Node Tools

- **`audit`** - Find dead code and over-abstractions (Node)

  ```bash
  inquisitor audit
  ```

- **`detox`** - Analyze and clean unused dependencies (Node)

  ```bash
  inquisitor detox
  ```

- **`viz`** - Start interactive dependency visualizer (Node)

  ```bash
  inquisitor viz
  ```

- **`ctx`** - Pack full project context for Gemini 2.5 (Node)
  ```bash
  inquisitor ctx:pack
  ```

Run `inquisitor --help` to see all available commands with descriptions.

## üêç Requirements

- **Node.js:** v18+
- **Python:** 3.10+ recommended, available in `PATH` as `python` (Windows) or `python3` (Unix).
- **OS:** Works on Windows, macOS, and Linux.

## ü§ù Development

1. Clone the repo.
2. Run `npm install` (installs TS deps and runs Python setup).
3. If Python setup fails, run `npm run setup:python` manually.
4. Build TypeScript:

   ```bash
   npm run build
   ```

5. **Do not commit** `venv/` or `__pycache__/`.

## üìÅ Project Structure

```
repo-inquisitor/
‚îú‚îÄ‚îÄ src/              # TypeScript source
‚îÇ   ‚îú‚îÄ‚îÄ cli.ts        # CLI entrypoint and command registry
‚îÇ   ‚îú‚îÄ‚îÄ bridge.ts     # PythonBridge implementation
‚îÇ   ‚îú‚îÄ‚îÄ ai/           # AI context packing utilities
‚îÇ   ‚îú‚îÄ‚îÄ analysis/     # Node.js analysis tools (audit, detox)
‚îÇ   ‚îî‚îÄ‚îÄ viz/          # Dependency visualization server
‚îú‚îÄ‚îÄ python_src/       # Python scripts
‚îÇ   ‚îú‚îÄ‚îÄ analyzer.py   # File statistics analyzer
‚îÇ   ‚îú‚îÄ‚îÄ police.py     # Pattern/style scanner
‚îÇ   ‚îî‚îÄ‚îÄ reviewer/     # AI code reviewer
‚îú‚îÄ‚îÄ bin/              # Binary symlinks (inq-audit, inq-detox, etc.)
‚îî‚îÄ‚îÄ dist/             # Compiled TypeScript output
```

## ‚ö†Ô∏è Notes & Limitations

- If Python is not in `PATH`, the install/setup scripts will fail fast on purpose.
- The `review` command requires `GEMINI_API_KEY` and `GITHUB_TOKEN` environment variables.
- Commands can be extended or modified in `src/cli.ts` by updating the `COMMANDS` registry.
- `requirements.txt` should contain only the Python dependencies you actually use.
</file>

<file path="requirements.txt">
# Python dependencies for repo-inquisitor


google-generativeai
PyGithub
</file>

<file path="scripts/install.js">
#!/usr/bin/env node
/**
 * Cross-platform Python environment setup script.
 * Detects OS, checks Python availability, creates venv, and installs dependencies.
 */

const { spawn } = require('child_process');
const fs = require('fs');
const path = require('path');
const os = require('os');

const IS_WINDOWS = os.platform() === 'win32';
const PYTHON_CMD = IS_WINDOWS ? 'python' : 'python3';
const VENV_DIR = path.join(__dirname, '..', 'venv');
const VENV_PYTHON = IS_WINDOWS 
  ? path.join(VENV_DIR, 'Scripts', 'python.exe')
  : path.join(VENV_DIR, 'bin', 'python');
const REQUIREMENTS = path.join(__dirname, '..', 'requirements.txt');

/**
 * Check if Python is available in PATH.
 * @returns {Promise<boolean>}
 */
function checkPython() {
  return new Promise((resolve) => {
    const proc = spawn(PYTHON_CMD, ['--version'], {
      stdio: 'pipe',
      shell: IS_WINDOWS
    });

    let output = '';
    proc.stdout.on('data', (data) => { output += data.toString(); });
    proc.stderr.on('data', (data) => { output += data.toString(); });

    proc.on('close', (code) => {
      if (code === 0) {
        console.log(`‚úì Found Python: ${output.trim()}`);
        resolve(true);
      } else {
        console.error(`‚úó Python not found. Please install Python 3.10+ and ensure it's in PATH.`);
        resolve(false);
      }
    });

    proc.on('error', () => {
      console.error(`‚úó Failed to execute '${PYTHON_CMD}'. Is Python installed?`);
      resolve(false);
    });
  });
}

/**
 * Create virtual environment.
 * @returns {Promise<boolean>}
 */
function createVenv() {
  return new Promise((resolve) => {
    if (fs.existsSync(VENV_DIR)) {
      console.log(`‚úì Virtual environment already exists at ${VENV_DIR}`);
      resolve(true);
      return;
    }

    console.log(`Creating virtual environment at ${VENV_DIR}...`);
    const proc = spawn(PYTHON_CMD, ['-m', 'venv', VENV_DIR], {
      stdio: 'inherit',
      shell: IS_WINDOWS
    });

    proc.on('close', (code) => {
      if (code === 0) {
        console.log(`‚úì Virtual environment created`);
        resolve(true);
      } else {
        console.error(`‚úó Failed to create virtual environment (exit code: ${code})`);
        resolve(false);
      }
    });

    proc.on('error', (err) => {
      console.error(`‚úó Failed to spawn venv creation: ${err.message}`);
      resolve(false);
    });
  });
}

/**
 * Install Python dependencies from requirements.txt.
 * @returns {Promise<boolean>}
 */
function installDependencies() {
  return new Promise((resolve) => {
    if (!fs.existsSync(REQUIREMENTS)) {
      console.log(`‚ö† requirements.txt not found, skipping dependency installation.`);
      resolve(true);
      return;
    }

    const requirementsContent = fs.readFileSync(REQUIREMENTS, 'utf8').trim();
    if (!requirementsContent) {
      console.log(`‚ö† requirements.txt is empty, skipping dependency installation.`);
      resolve(true);
      return;
    }

    if (!fs.existsSync(VENV_PYTHON)) {
      console.error(`‚úó Virtual environment Python not found at ${VENV_PYTHON}`);
      resolve(false);
      return;
    }

    console.log(`Installing Python dependencies from ${REQUIREMENTS}...`);
    const proc = spawn(VENV_PYTHON, ['-m', 'pip', 'install', '-r', REQUIREMENTS], {
      stdio: 'inherit',
      shell: IS_WINDOWS,
      cwd: path.join(__dirname, '..')
    });

    proc.on('close', (code) => {
      if (code === 0) {
        console.log(`‚úì Python dependencies installed`);
        resolve(true);
      } else {
        console.error(`‚úó Failed to install dependencies (exit code: ${code})`);
        resolve(false);
      }
    });

    proc.on('error', (err) => {
      console.error(`‚úó Failed to spawn pip install: ${err.message}`);
      resolve(false);
    });
  });
}

/**
 * Main installation flow.
 */
async function main() {
  console.log('üîß Setting up Python environment...\n');

  if (!(await checkPython())) {
    process.exit(1);
  }

  if (!(await createVenv())) {
    process.exit(1);
  }

  if (!(await installDependencies())) {
    process.exit(1);
  }

  console.log('\n‚úì Python environment setup complete!');
}

if (require.main === module) {
  main().catch((err) => {
    console.error('Fatal error:', err);
    process.exit(1);
  });
}

module.exports = { checkPython, createVenv, installDependencies };
</file>

<file path="setup.sh">
#!/bin/bash
# setup.sh - Script –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ–µ–∫—Ç–∞

echo "Installing Node.js dependencies..."
npm install

echo "Installing Python dependencies..."
pip install -r requirements.txt

echo "Setup complete!"
</file>

<file path="src/types.ts">
export interface PythonExecutionResult<T = unknown> {
  success: boolean;
  data?: T;
  error?: string;
  logs?: string[];
}

export interface BridgeOptions {
  pythonPath?: string;
  cwd?: string;
  env?: Record<string, string>;
}
</file>

<file path="src/viz/py_parser.py">
import ast
import os
import sys
import json
from pathlib import Path

def get_imports(file_path):
    imports = []
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            tree = ast.parse(f.read(), filename=file_path)
        
        base_dir = os.path.dirname(file_path)
        
        for node in ast.walk(tree):
            if isinstance(node, ast.Import):
                for alias in node.names:
                    imports.append(alias.name)
            elif isinstance(node, ast.ImportFrom):
                if node.module:
                    imports.append(node.module)
                elif node.level > 0:
                    imports.append('.' * node.level)
    except Exception:
        pass # Ignore syntax errors in work-in-progress files
    return imports

def scan_project(root_dir):
    graph = {}
    root_path = Path(root_dir).resolve()

    for root, _, files in os.walk(root_dir):
        for file in files:
            if file.endswith('.py') and '.venv' not in root:
                full_path = Path(os.path.join(root, file))
                rel_path = str(full_path.relative_to(root_path)).replace('\\', '/')
                
                raw_imports = get_imports(str(full_path))
                
                resolved_deps = []
                for imp in raw_imports:
                    possible_path = imp.replace('.', '/') + '.py'
                    if (root_path / possible_path).exists():
                         resolved_deps.append(possible_path)
                    elif (full_path.parent / possible_path).exists():
                         dep_abs = (full_path.parent / possible_path).resolve()
                         try:
                             dep_rel = str(dep_abs.relative_to(root_path)).replace('\\', '/')
                             resolved_deps.append(dep_rel)
                         except ValueError:
                             pass

                graph[rel_path] = resolved_deps

    print(json.dumps(graph))

if __name__ == '__main__':
    scan_project(sys.argv[1])
</file>

<file path="src/viz/server.cjs">
const express = require("express");
const http = require("http");
const { Server } = require("socket.io");
const chokidar = require("chokidar");
const madge = require("madge");
const { spawn } = require("child_process");
const path = require("path");

const PORT = 3000;
const ROOT_DIR = path.resolve(__dirname, "../../");
const SRC_DIR = path.join(ROOT_DIR, "src");

const app = express();
const server = http.createServer(app);
const io = new Server(server);

let lastGraphData = null;

io.on("connection", (socket) => {
  console.log("üîå Client connected");
  if (lastGraphData) {
    socket.emit("graph-data", lastGraphData);
  } else {
    // First build might be in progress or not started
    buildGraph().then((data) => {
      lastGraphData = data;
      socket.emit("graph-data", data);
    });
  }
});

const HTML_CONTENT = `
<!DOCTYPE html>
<html>
<head>
    <title>Code Dependency Graph</title>
    <script src="https://unpkg.com/vis-network/standalone/umd/vis-network.min.js"></script>
    <script src="/socket.io/socket.io.js"></script>
    <style>
        body { margin: 0; font-family: sans-serif; background: #1e1e1e; color: #ccc; overflow: hidden; }
        #mynetwork { width: 100vw; height: 100vh; }
        #controls { position: absolute; top: 10px; left: 10px; background: rgba(0,0,0,0.7); padding: 10px; border-radius: 8px; z-index: 100; }
        .legend-item { display: flex; align-items: center; margin-bottom: 4px; font-size: 12px; }
        .dot { width: 10px; height: 10px; border-radius: 50%; margin-right: 8px; }
        button { background: #333; color: white; border: 1px solid #555; padding: 5px 10px; cursor: pointer; }
        button:hover { background: #444; }
        #status { font-size: 12px; color: #888; margin-top: 5px; }
    </style>
</head>
<body>
    <div id="controls">
        <h3 style="margin-top:0">Dependency Map</h3>
        <div class="legend-item"><div class="dot" style="background:#97C2FC"></div>TypeScript</div>
        <div class="legend-item"><div class="dot" style="background:#FFD700"></div>Python</div>
        <div class="legend-item"><div class="dot" style="background:#FB7E81"></div>Orphan (No deps)</div>
        <hr style="border-color: #444;">
        <button onclick="fitGraph()">Fit Graph</button>
        <button onclick="togglePhysics()">Toggle Physics</button>
        <div id="status">Connecting...</div>
    </div>
    <div id="mynetwork"></div>

    <script>
        const socket = io();
        let network = null;
        let physicsEnabled = true;

        const options = {
            nodes: { 
                shape: 'dot', 
                size: 16,
                font: { color: '#ffffff', size: 14, strokeWidth: 2, strokeColor: '#000000' }
            },
            edges: {
                color: { color: '#555555', highlight: '#00ff00' },
                arrows: { to: { enabled: true, scaleFactor: 0.5 } },
                smooth: { type: 'continuous' }
            },
            physics: {
                stabilization: false,
                barnesHut: { gravitationalConstant: -2000, springConstant: 0.04, springLength: 95 }
            },
            layout: { randomSeed: 2 }
        };

        socket.on('graph-data', (data) => {
            const statusEl = document.getElementById('status');
            if(statusEl) statusEl.innerText = 'Nodes: ' + data.nodes.length;
            drawGraph(data.nodes, data.edges);
        });

        function drawGraph(nodesData, edgesData) {
            const container = document.getElementById('mynetwork');
            const data = { nodes: new vis.DataSet(nodesData), edges: new vis.DataSet(edgesData) };
            
            if (!network) {
                network = new vis.Network(container, data, options);
                network.on("click", function (params) {
                    if (params.nodes.length > 0) {
                        console.log("Selected:", params.nodes[0]);
                    }
                });
            } else {
                network.setData(data);
            }
        }

        function fitGraph() { network.fit(); }
        function togglePhysics() {
            physicsEnabled = !physicsEnabled;
            network.setOptions({ physics: physicsEnabled });
        }
    </script>
</body>
</html>
`;

app.get("/", (req, res) => res.send(HTML_CONTENT));

async function getTSGraph() {
  try {
    const res = await madge(SRC_DIR, {
      fileExtensions: ["ts", "tsx"],
      tsConfig: path.join(ROOT_DIR, "tsconfig.json"),
    });
    return res.obj();
  } catch (e) {
    console.error("Madge Error:", e);
    return {};
  }
}

function getPyGraph() {
  return new Promise((resolve) => {
    const pyScript = path.join(__dirname, "py_parser.py");
    const pythonProcess = spawn("python", [pyScript, SRC_DIR]);

    let data = "";
    pythonProcess.stdout.on("data", (chunk) => (data += chunk));

    pythonProcess.on("close", (code) => {
      try {
        resolve(JSON.parse(data));
      } catch (e) {
        console.error("Python parse error (JSON)");
        resolve({});
      }
    });
  });
}

async function buildGraph() {
  console.log("üîÑ Rebuilding graph...");
  const [tsDeps, pyDeps] = await Promise.all([getTSGraph(), getPyGraph()]);

  const nodes = [];
  const edges = [];
  const nodeSet = new Set();

  const addNode = (id, type) => {
    if (!nodeSet.has(id)) {
      let color = type === "ts" ? "#97C2FC" : "#FFD700";
      nodes.push({
        id,
        label: path.basename(id),
        title: id,
        color: color,
        group: type,
      });
      nodeSet.add(id);
    }
  };

  for (const [file, deps] of Object.entries(tsDeps)) {
    addNode(file, "ts");
    deps.forEach((dep) => {
      addNode(dep, "ts");
      edges.push({ from: file, to: dep });
    });
  }

  for (const [file, deps] of Object.entries(pyDeps)) {
    addNode(file, "py");
    deps.forEach((dep) => {
      addNode(dep, "py");
      edges.push({ from: file, to: dep });
    });
  }

  nodes.forEach((n) => {
    const hasEdges = edges.some((e) => e.from === n.id || e.to === n.id);
    if (!hasEdges) n.color = "#FB7E81";
  });

  return { nodes, edges };
}

let debounceTimer;
const triggerUpdate = () => {
  clearTimeout(debounceTimer);
  debounceTimer = setTimeout(async () => {
    const data = await buildGraph();
    lastGraphData = data;
    io.emit("graph-data", data);
    console.log(`‚úÖ Graph updated: ${data.nodes.length} nodes`);
  }, 1000);
};

chokidar
  .watch(SRC_DIR, { ignored: /node_modules|\.git|dist|out/ })
  .on("all", (event, path) => {
    if (path.endsWith(".ts") || path.endsWith(".tsx") || path.endsWith(".py")) {
      triggerUpdate();
    }
  });

const start = async () => {
  try {
    const { default: open } = await import("open");

    server.listen(PORT, () => {
      console.log(`üöÄ Visualizer running at http://localhost:${PORT}`);
      open(`http://localhost:${PORT}`);
      triggerUpdate(); // First run
    });
  } catch (err) {
    console.error("Failed to start server:", err);
  }
};

start();
</file>

<file path="python_src/utils/io_helper.py">
import sys
import json
from typing import Any, List, Optional

def emit_log(message: str):
    print(message)
    sys.stdout.flush()

def emit_success(data: Any = None, logs: Optional[List[str]] = None):
    if logs:
        for log in logs:
            print(log)
            
    response = {
        "status": "success",
        "data": data
    }
    sys.stdout.flush()
    print(json.dumps(response))
    sys.exit(0)

def emit_error(message: str, details: Any = None):
    sys.stderr.write(message + "\n")
    if details:
        sys.stderr.write(json.dumps(details) + "\n")
    sys.exit(1)
</file>

</files>
